from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage

def call_model(question, human_message, system_message ):
    """
    Calls a language model to generate a structured response based on the provided question, human message, and system message.
    Args:
        question (str): The question or prompt to structure the model's output.
        human_message (str): The content of the human message to provide as input to the model.
        system_message (str): The content of the system message to provide as context to the model.
    Returns:
        Any: The structured response generated by the language model.
    """
     
    #deepseek-r1:8b #llama3.2
    llm = ChatOllama(model="deepseek-r1:8b", num_predict = 100 )
    structured_llm = llm.with_structured_output(
        question
    )
    response = structured_llm.invoke([
        HumanMessage(content=human_message),
        SystemMessage(
            content=system_message
            )
    ])
    return response




